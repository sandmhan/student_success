{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Alcohol Consumption\n",
    "Link: https://www.kaggle.com/datasets/uciml/student-alcohol-consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# There is two data sets, one for math grades, the other for portuguese\n",
    "math_df = pd.read_csv('Datasets/Student Alcohol Consumption/student-mat.csv')\n",
    "por_df =  pd.read_csv('Datasets/Student Alcohol Consumption/student-por.csv')\n",
    "\n",
    "# print(np.shape(math_df))        # Shape [395, 33]\n",
    "# print(np.shape(portuguese_df))  # Shape [649, 33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal here is to predict the student's grades (both math and portuguese) using relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to parse the data set so the values can be used (i.e. yes/no should be changed to 1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n"
     ]
    }
   ],
   "source": [
    "# Moving around the columns for the grade results [G1, G2, G3] to the end of the data frame so it's easier to process.\n",
    "math_df = math_df[[c for c in math_df if c not in ['G1', 'G2', 'G3']] + ['G1', 'G2', 'G3']]\n",
    "print(math_df.columns.tolist())\n",
    "# print(math_df.iloc[0, :])\n",
    "\n",
    "# Do one-hot encoding on columns populated by strings\n",
    "feat_to_one_hot_encode = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
    "math_df = pd.get_dummies(math_df, prefix=feat_to_one_hot_encode)\n",
    "\n",
    "# Standardize certain columns\n",
    "feat_to_standardize = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
    "for feat in feat_to_standardize:\n",
    "    math_df[feat] = (math_df[feat] - math_df[feat].mean()) / math_df[feat].std()\n",
    "\n",
    "# # Turning them into ndarrays\n",
    "# math_features = math_df.iloc[:, :math_df.shape[1] - 3].values\n",
    "# math_labels = math_df.loc[:, 'G3'].values # Chosed G3 because it's the final grade for the subject, but adding in the others isn't difficult\n",
    "# print(math_df.shape)\n",
    "# print(math_features.shape)\n",
    "# print(math_labels.shape)\n",
    "clone = math_df\n",
    "clone = clone.drop('G3', axis=1)\n",
    "math_features = clone.iloc[:].values\n",
    "math_labels = math_df.loc[:, 'G3'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a data frame, generate the training/validation set's features and labels\n",
    "# The training/validation set are ndarrays, not a data frame since I'm trying to make it work with the KNN function beyond this step\n",
    "def generateRandom(data, features, labels):\n",
    "  perm_idx = np.random.permutation(data.shape[0])\n",
    "  vali_num = int(data.shape[0] * 0.2)\n",
    "  vali_idx = perm_idx[:vali_num]\n",
    "  train_idx = perm_idx[vali_num:]\n",
    "  train_features = features[train_idx, :]\n",
    "  train_labels = labels[train_idx]\n",
    "  vali_features = features[vali_idx, :]\n",
    "  vali_labels = labels[vali_idx]\n",
    "  return train_features, train_labels, vali_features, vali_labels\n",
    "\n",
    "math_train_features, math_train_labels, math_vali_features, math_vali_labels = generateRandom(math_df, math_features, math_labels)\n",
    "# print(math_train_features.shape)\n",
    "# print(math_vali_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 5, Accuracy: 0.6708860759493671\n",
      "K: 6, Accuracy: 0.6582278481012658\n",
      "K: 7, Accuracy: 0.6835443037974683\n",
      "K: 8, Accuracy: 0.6835443037974683\n",
      "K: 9, Accuracy: 0.6708860759493671\n",
      "K: 10, Accuracy: 0.6708860759493671\n",
      "K: 11, Accuracy: 0.6835443037974683\n",
      "K: 12, Accuracy: 0.6582278481012658\n",
      "K: 13, Accuracy: 0.6455696202531646\n",
      "K: 14, Accuracy: 0.6582278481012658\n",
      "K: 15, Accuracy: 0.6582278481012658\n"
     ]
    }
   ],
   "source": [
    "def KNN(train_features, train_labels, test_features, k=10):\n",
    "    vali_pred = []\n",
    "    for i in range(test_features.shape[0]):\n",
    "        x = test_features[i, :]  \n",
    "        distances = np.sqrt(np.sum((x - train_features) ** 2, axis=1))\n",
    "        topk_idx = np.argpartition(distances, k)[:k]\n",
    "        topk_labels = list(train_labels[topk_idx])\n",
    "        pred = max(topk_labels, key=topk_labels.count)\n",
    "        vali_pred.append(pred)\n",
    "    return np.array(vali_pred)\n",
    "\n",
    "for k_tuner in range(5, 16):\n",
    "    # Grabbing predictions\n",
    "    math_vali_pred = KNN(math_train_features, math_train_labels, math_vali_features, k=k_tuner)\n",
    "\n",
    "    # Some calculations for accuracy\n",
    "    count = 0\n",
    "    margin = 1  # For when the guess is close, but not quite exact\n",
    "    for i in range(math_vali_pred.size):\n",
    "        # print(str(math_vali_pred[i]) + ' ' +str(math_vali_labels[i]))\n",
    "        if math_vali_labels[i] - margin <= math_vali_pred[i] and math_vali_pred[i] <= math_vali_labels[i] + margin:\n",
    "            count += 1\n",
    "\n",
    "    print(\"K: {}, Accuracy: {}\".format(k_tuner, str(count / math_vali_features.shape[0])))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy has been improved to > 90% by standardizing certain columns and performing one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "# Medu\n",
    "# Fedu\n",
    "# traveltime\n",
    "# studytime\n",
    "\n",
    "# failures\n",
    "# famrel\n",
    "# freetime\n",
    "# goout\n",
    "# Dalc\n",
    "\n",
    "# Walc\n",
    "# health\n",
    "# absences\n",
    "# G1\n",
    "# G2\n",
    "\n",
    "# school_GP\n",
    "# school_MS\n",
    "# sex_F\n",
    "# sex_M\n",
    "# address_R\n",
    "# address_U\n",
    "# famsize_GT3\n",
    "# famsize_LE3\n",
    "# Pstatus_A\n",
    "# Pstatus_T\n",
    "# Mjob_at_home\n",
    "# Mjob_health\n",
    "# Mjob_other\n",
    "# Mjob_services\n",
    "# Mjob_teacher\n",
    "# Fjob_at_home\n",
    "# Fjob_health\n",
    "# Fjob_other\n",
    "# Fjob_services\n",
    "# Fjob_teacher\n",
    "# reason_course\n",
    "# reason_home\n",
    "# reason_other\n",
    "# reason_reputation\n",
    "# guardian_father\n",
    "# guardian_mother\n",
    "# guardian_other\n",
    "# schoolsup_no\n",
    "# schoolsup_yes\n",
    "# famsup_no\n",
    "# famsup_yes\n",
    "# paid_no\n",
    "# paid_yes\n",
    "# activities_no\n",
    "# activities_yes\n",
    "# nursery_no\n",
    "# nursery_yes\n",
    "# higher_no\n",
    "# higher_yes\n",
    "# internet_no\n",
    "# internet_yes\n",
    "# romantic_no\n",
    "# romantic_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSample = [[-1.32926782,  1.14240684, -0.47924897, -0.64243471,  -1, #Study Time\n",
    "       -0.44937373, -1.05313638, -1.23685052, -0.99603207, -0.54001379,\n",
    "       -1.00251779,  1.0397512 , -0.46342827, 15., 14.,\n",
    "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
    "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
    "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
    "        1.,  0.,  1.], \n",
    "        [-1.32926782,  1.14240684, -0.47924897, -0.64243471,  0,\n",
    "       -0.44937373, -1.05313638, -1.23685052, -0.99603207, -0.54001379,\n",
    "       -1.00251779,  1.0397512 , -0.46342827, 15., 14.,\n",
    "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
    "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
    "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
    "        1.,  0.,  1.],\n",
    "        [-1.32926782,  1.14240684, -0.47924897, -0.64243471,  1,\n",
    "       -0.44937373, -1.05313638, -1.23685052, -0.99603207, -0.54001379,\n",
    "       -1.00251779,  1.0397512 , -0.46342827, 15., 14.,\n",
    "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
    "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
    "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
    "        1.,  0.,  1.],\n",
    "        [-1.32926782,  1.14240684, -0.47924897, -0.64243471,  1.14932149, #Health \n",
    "       -0.44937373, -1.05313638, -1.23685052, -0.99603207, -0.54001379,\n",
    "       -1.00251779,  -1 , -0.46342827, 15., 14.,\n",
    "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
    "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
    "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
    "        1.,  0.,  1.],\n",
    "        [-1.32926782,  1.14240684, -0.47924897, -0.64243471,  1.14932149,\n",
    "       -0.44937373, -1.05313638, -1.23685052, -0.99603207, -0.54001379,\n",
    "       -1.00251779,  0 , -0.46342827, 15., 14.,\n",
    "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
    "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
    "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
    "        1.,  0.,  1.],\n",
    "        [-1.32926782,  1.14240684, -0.47924897, -0.64243471,  1.14932149,\n",
    "       -0.44937373, -1.05313638, -1.23685052, -0.99603207, -0.54001379,\n",
    "       -1.00251779,  1 , -0.46342827, 15., 14.,\n",
    "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
    "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
    "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
    "        1.,  0.,  1.],\n",
    "        [-1.32926782,  1.14240684, -0.47924897, -0.64243471,  1.14932149, #Absences \n",
    "       -0.44937373, -1.05313638, -1.23685052, -0.99603207, -0.54001379,\n",
    "       -1.00251779,  1.0397512 , -1, 15., 14.,\n",
    "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
    "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
    "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
    "        1.,  0.,  1.],\n",
    "        [-1.32926782,  1.14240684, -0.47924897, -0.64243471,  1.14932149,  \n",
    "       -0.44937373, -1.05313638, -1.23685052, -0.99603207, -0.54001379,\n",
    "       -1.00251779,  1.0397512 , 0, 15., 14.,\n",
    "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
    "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
    "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
    "        1.,  0.,  1.],[-1.32926782,  1.14240684, -0.47924897, -0.64243471,  1.14932149,  \n",
    "       -0.44937373, -1.05313638, -1.23685052, -0.99603207, -0.54001379,\n",
    "       -1.00251779,  1.0397512 , 1, 15., 14.,\n",
    "        1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
    "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
    "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
    "        1.,  0.,  1.],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 14, 14, 14, 15, 14, 14, 14, 15], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sample =  KNN(math_train_features, math_train_labels, np.array(testSample), k=k_tuner)\n",
    "pred_sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Alcohol Consumption\n",
    "Link: https://www.kaggle.com/datasets/uciml/student-alcohol-consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# There is two data sets, one for math grades, the other for portuguese\n",
    "math_df = pd.read_csv('Datasets/Student Alcohol Consumption/student-mat.csv')\n",
    "por_df =  pd.read_csv('Datasets/Student Alcohol Consumption/student-por.csv')\n",
    "\n",
    "# print(np.shape(math_df))        # Shape [395, 33]\n",
    "# print(np.shape(portuguese_df))  # Shape [649, 33]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal here is to predict the student's grades (both math and portuguese) using relevant features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to parse the data set so the values can be used (i.e. yes/no should be changed to 1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all binary features into 1/0\n",
    "def formatDf(df):\n",
    "  # Identify columns with only two unique values\n",
    "  binary_cols = []\n",
    "  for col in df.columns:\n",
    "    unique_vals = df[col].unique()\n",
    "    if len(unique_vals) == 2:\n",
    "      binary_cols.append(col)\n",
    "\n",
    "  # Convert binary values to 1 and 0\n",
    "  for col in binary_cols:\n",
    "        df[col] = df[col].apply(lambda x: 1 if x == df[col].unique()[0] else 0)\n",
    "  return df\n",
    "\n",
    "math_df = formatDf(math_df)\n",
    "math_df = pd.get_dummies(math_df)\n",
    "\n",
    "# Moving around the columns for the grade results [G1, G2, G3] to the end of the data frame so it's easier to process.\n",
    "cols = math_df.columns.tolist()\n",
    "cols = cols[:26] + cols[29:] + cols[26:29]\n",
    "math_df = math_df[cols]\n",
    "# print(math_df.iloc[0, :])\n",
    "\n",
    "# Turning them into ndarrays\n",
    "math_features = math_df.iloc[:, :math_df.shape[1] - 3].values\n",
    "math_labels = math_df.loc[:, 'G3'].values # Chosed G3 because it's the final grade for the subject, but adding in the others isn't difficult\n",
    "# print(math_df.shape)\n",
    "# print(math_features.shape)\n",
    "# print(math_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a data frame, generate the training/validation set's features and labels\n",
    "# The training/validation set are ndarrays, not a data frame since I'm trying to make it work with the KNN function beyond this step\n",
    "def generateRandom(data, features, labels):\n",
    "  perm_idx = np.random.permutation(data.shape[0])\n",
    "  vali_num = int(data.shape[0] * 0.2)\n",
    "  vali_idx = perm_idx[:vali_num]\n",
    "  train_idx = perm_idx[vali_num:]\n",
    "  train_features = math_features[train_idx, :]\n",
    "  train_labels = math_labels[train_idx]\n",
    "  vali_features = math_features[vali_idx, :]\n",
    "  vali_labels = math_labels[vali_idx]\n",
    "  return train_features, train_labels, vali_features, vali_labels\n",
    "\n",
    "math_train_features, math_train_labels, math_vali_features, math_vali_labels = generateRandom(math_df, math_features, math_labels)\n",
    "# print(math_train_features.shape)\n",
    "# print(math_vali_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3291139240506329\n"
     ]
    }
   ],
   "source": [
    "def KNN(train_features, train_labels, test_features, k=10):\n",
    "    vali_pred = []\n",
    "    for i in range(test_features.shape[0]):\n",
    "        x = test_features[i, :]  \n",
    "        distances = np.sqrt(np.sum((x - train_features) ** 2, axis=1))\n",
    "        topk_idx = np.argpartition(distances, k)[:k]\n",
    "        topk_labels = list(train_labels[topk_idx])\n",
    "        pred = max(topk_labels, key=topk_labels.count)\n",
    "        vali_pred.append(pred)\n",
    "    return np.array(vali_pred)\n",
    "\n",
    "# Grabbing predictions\n",
    "math_vali_pred = KNN(math_train_features, math_train_labels, math_vali_features, k=10)\n",
    "\n",
    "# Some calculations for accuracy\n",
    "count = 0\n",
    "margin = 1  # For when the guess is close, but not quite exact\n",
    "for i in range(math_vali_pred.size):\n",
    "    # print(str(math_vali_pred[i]) + ' ' +str(math_vali_labels[i]))\n",
    "    if math_vali_pred[i] + margin == math_vali_labels[i] or math_vali_pred[i] - margin == math_vali_labels[i] or math_vali_pred[i] == math_vali_labels[i]:\n",
    "        count += 1\n",
    "\n",
    "print(\"Accuracy: \" + str(count / math_vali_features.shape[0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very inaccurate, this is possible due to the many features that might not necessarily relate to one another, making it so that judging distances between points isn't the best way to approach this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs484",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
